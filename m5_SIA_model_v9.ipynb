{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "m5 SIA_model_v9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/speakerv/Testing/blob/master/m5_SIA_model_v9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "lines_to_next_cell": 2,
        "title": "[code]",
        "trusted": true,
        "id": "3Z7Z_zHPC4Rq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import gc\n",
        "import warnings\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.plotting import register_matplotlib_converters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import plotly.figure_factory as ff\n",
        "from plotly.subplots import make_subplots\n",
        "\n",
        "from scipy.optimize import minimize\n",
        "from IPython.display import Audio\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option(\"display.max_columns\", 500)\n",
        "pd.set_option(\"display.max_rows\", 500)\n",
        "register_matplotlib_converters()\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JtIQKeezIh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, io\n",
        "#The copied URL goes here ->\n",
        "r = requests.get( 'https://github.com/speakerv/Testing/blob/master/M5.zip?raw=true' ) \n",
        "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "z.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "[code]",
        "trusted": true,
        "id": "m7ouELBOC4Rx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import IPython\n",
        "\n",
        "def display(*dfs, head=True):\n",
        "    for df in dfs:\n",
        "        IPython.display.display(df.head() if head else df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "[code]",
        "trusted": true,
        "id": "7d8v8kXzC4R1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_kaggle():\n",
        "    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "[code]",
        "trusted": true,
        "id": "vcZugCtUC4R5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if on_kaggle():\n",
        "    os.system(\"pip install --quiet mlflow_extend\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "[code]",
        "trusted": true,
        "id": "zUR7DE6vC4R-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def reduce_mem_usage(df, verbose=False):\n",
        "    start_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    int_columns = df.select_dtypes(include=[\"int\"]).columns\n",
        "    float_columns = df.select_dtypes(include=[\"float\"]).columns\n",
        "\n",
        "    for col in int_columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast=\"integer\")\n",
        "\n",
        "    for col in float_columns:\n",
        "        df[col] = pd.to_numeric(df[col], downcast=\"float\")\n",
        "\n",
        "    end_mem = df.memory_usage().sum() / 1024 ** 2\n",
        "    if verbose:\n",
        "        print(\n",
        "            \"Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)\".format(\n",
        "                end_mem, 100 * (start_mem - end_mem) / start_mem\n",
        "            )\n",
        "        )\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "[code]",
        "trusted": true,
        "id": "XWOtChR0C4SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_data():\n",
        "    INPUT_DIR = \"/kaggle/input\" if on_kaggle() else \"input\"\n",
        "    INPUT_DIR = f\"{INPUT_DIR}/m5-forecasting-accuracy\"\n",
        "\n",
        "    print(\"Reading files...\")\n",
        "\n",
        "    calendar = pd.read_csv(f\"{INPUT_DIR}/calendar.csv\").pipe(reduce_mem_usage)\n",
        "    prices = pd.read_csv(f\"{INPUT_DIR}/sell_prices.csv\").pipe(reduce_mem_usage)\n",
        "\n",
        "    sales = pd.read_csv(f\"{INPUT_DIR}/sales_train_validation.csv\",).pipe(\n",
        "        reduce_mem_usage\n",
        "    )\n",
        "    submission = pd.read_csv(f\"{INPUT_DIR}/sample_submission.csv\").pipe(\n",
        "        reduce_mem_usage\n",
        "    )\n",
        "\n",
        "    print(\"sales shape:\", sales.shape)\n",
        "    print(\"prices shape:\", prices.shape)\n",
        "    print(\"calendar shape:\", calendar.shape)\n",
        "    print(\"submission shape:\", submission.shape)\n",
        "\n",
        "    # calendar shape: (1969, 14)\n",
        "    # sell_prices shape: (6841121, 4)\n",
        "    # sales_train_val shape: (30490, 1919)\n",
        "    # submission shape: (60980, 29)\n",
        "\n",
        "    return sales, prices, calendar, submission"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Q5gTi8qnC4SH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# type(train_data)\n",
        "# train_data['Value'][10]\n",
        "\n",
        "# temp_data=train_data.drop(index=np.arange(0,10,1).tolist()) \n",
        "\n",
        "# print(temp_data)\n",
        "# print(train_data)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7SHlyx3wC4SM",
        "colab_type": "code",
        "outputId": "dba4b0d4-968e-4a41-c96f-fd4813b53cd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# INPUT_DIR = \"output/kaggle/working\"\n",
        "# train_data=sales.loc[0][6:].to_frame()\n",
        "# train_data.columns=['Value']\n",
        "# train_data\n",
        "# train_data.to_csv(\"test1_train_data.csv\",index=True)\n",
        "\n",
        "train_data=pd.read_csv(\"/content/test1_train_data.csv\")\n",
        "train_data['Value']\n",
        "\n",
        "# plt.plot(train_data.index,train_data['Value'])\n",
        "# fig_size = plt.rcParams[\"figure.figsize\"]\n",
        "# fig_size[0] = 500\n",
        "# fig_size[1] = 500\n",
        "# plt.rcParams[\"figure.figsize\"] = fig_size\n",
        "# train_data.shape[0]\n",
        "\n",
        "fig = go.Figure()\n",
        "# x = np.arange(len(prediction))\n",
        "fig.add_trace(go.Scatter(x=train_data.index.values,\n",
        "                         y=train_data['Value'],\n",
        "                         name ='pre_interval')) \n",
        "fig.show()\n",
        "\n",
        "num_for_zeros_window=10\n",
        "counter_zeros_in_sequence = 0 \n",
        "flag_start_count=False\n",
        "for i in train_data.index.values:\n",
        "      \n",
        "    if train_data['Value'][i] != 0 and flag_start_count:\n",
        "        flag_start_count = False \n",
        "        if counter_zeros_in_sequence >= num_for_zeros_window:\n",
        "#             print('point 4')\n",
        "            train_data=train_data.drop(index=np.arange(left_index,right_index).tolist())                   \n",
        "                       \n",
        "    \n",
        "    if train_data['Value'][i] == 0 and flag_start_count:\n",
        "#         print('point 2')\n",
        "        counter_zeros_in_sequence += 1\n",
        "        right_index=i\n",
        "        \n",
        "    \n",
        "    if train_data['Value'][i] == 0 and not(flag_start_count):\n",
        "#         print('point 1')\n",
        "        flag_start_count = True\n",
        "        counter_zeros_in_sequence = 1\n",
        "        left_index=i\n",
        "\n",
        "fig = go.Figure()\n",
        "# x = np.arange(len(prediction))\n",
        "fig.add_trace(go.Scatter(x=train_data.index.values,\n",
        "                         y=train_data['Value'],\n",
        "                         name ='pre_interval')) \n",
        "    \n",
        "    "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0eb0157d-d228-4380-b3f5-e4373ac79ed2\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0eb0157d-d228-4380-b3f5-e4373ac79ed2\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0eb0157d-d228-4380-b3f5-e4373ac79ed2',\n",
              "                        [{\"name\": \"pre_interval\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912], \"y\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 2, 3, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 3, 0, 0, 3, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 3, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 3, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 3, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 2, 4, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 1, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 3, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 2, 0, 0, 1, 0, 0, 1, 3, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 2, 1, 1, 1, 0, 2, 2, 2, 1, 0, 0, 0, 1, 2, 0, 0, 1, 2, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 3, 1, 1, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 4, 2, 1, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 3, 0, 1, 2, 1, 0, 3, 0, 0, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 1, 0, 1, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 0, 0, 1, 4, 0, 0, 0, 0, 1, 1, 2, 0, 4, 0, 1, 0, 1, 4, 2, 0, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 3, 0, 0, 0, 1, 1, 1, 3, 1, 3, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 4, 2, 3, 0, 1, 2, 0, 0, 0, 1, 1, 3, 0, 1, 1, 1, 3, 0, 1, 1]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0eb0157d-d228-4380-b3f5-e4373ac79ed2');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"1de4e092-8ef8-4c30-9fe8-d282621ce02f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"1de4e092-8ef8-4c30-9fe8-d282621ce02f\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '1de4e092-8ef8-4c30-9fe8-d282621ce02f',\n",
              "                        [{\"name\": \"pre_interval\", \"type\": \"scatter\", \"x\": [900, 901, 915, 916, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1163, 1164, 1165, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1880, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912], \"y\": [0, 1, 0, 2, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 2, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 2, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 2, 3, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 1, 0, 0, 1, 1, 2, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 3, 0, 0, 3, 0, 1, 1, 2, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 2, 1, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 3, 1, 2, 2, 1, 1, 0, 0, 2, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 3, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 2, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 1, 0, 1, 2, 2, 0, 0, 0, 0, 2, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 2, 0, 0, 2, 0, 1, 3, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 3, 0, 2, 0, 0, 0, 0, 3, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 3, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 2, 4, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 1, 5, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 0, 2, 0, 2, 1, 0, 1, 0, 1, 1, 0, 0, 0, 2, 1, 1, 0, 0, 1, 0, 3, 0, 0, 0, 1, 0, 0, 2, 1, 0, 1, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 2, 2, 2, 0, 0, 1, 0, 0, 1, 3, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 2, 1, 1, 1, 0, 2, 2, 2, 1, 0, 0, 0, 1, 2, 0, 0, 1, 2, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 2, 1, 0, 2, 0, 1, 0, 0, 0, 1, 1, 2, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 3, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 2, 0, 0, 0, 1, 0, 2, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 3, 1, 1, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 0, 0, 4, 2, 1, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 1, 2, 1, 1, 0, 0, 2, 0, 2, 2, 0, 0, 0, 1, 1, 0, 2, 0, 1, 1, 2, 0, 1, 0, 0, 0, 2, 1, 0, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 3, 1, 1, 0, 1, 1, 2, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 3, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1, 2, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 3, 0, 1, 2, 1, 0, 3, 0, 0, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 1, 0, 1, 4, 0, 0, 5, 0, 0, 0, 0, 0, 0, 2, 1, 2, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 2, 2, 0, 0, 1, 4, 0, 0, 0, 0, 1, 1, 2, 0, 4, 0, 1, 0, 1, 4, 2, 0, 2, 0, 1, 1, 0, 1, 0, 0, 1, 1, 3, 0, 0, 0, 1, 1, 1, 3, 1, 3, 1, 2, 2, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 4, 2, 3, 0, 1, 2, 0, 0, 0, 1, 1, 3, 0, 1, 1, 1, 3, 0, 1, 1]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1de4e092-8ef8-4c30-9fe8-d282621ce02f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2fg83iAzC4ST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making random not only in order?\n",
        "def generate_random_batch(series, size=DAYS_PRED):      \n",
        "    \n",
        "    left_non_zero_index=0\n",
        "    right_index=series.shape[0]-2*size    \n",
        "    \n",
        "    while series.iloc[left_non_zero_index, 1]==0:\n",
        "        left_non_zero_index +=1\n",
        "\n",
        "    r_i=np.random.randint(left_non_zero_index,right_index)\n",
        "#     r_i=900 #for overfiting traingin\n",
        "    batch_1=[]\n",
        "    batch_2=[]\n",
        "    \n",
        "    batch_1=series.iloc[r_i:(r_i+size),1]\n",
        "    batch_2=series.iloc[r_i+size:r_i+size*2,1]\n",
        "    \n",
        "    return batch_1, batch_2, r_i\n",
        "\n",
        "# batch_1, batch_2, r_i=generate_random_batch(train_data)\n",
        "# print(batch_1)\n",
        "# print(batch_2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5Mh46IspC4SX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validation(model,display=False,display_figure=False):\n",
        "#     prediction_2=[]\n",
        "    y=[]\n",
        "    summation=[]\n",
        "#   for i in range(1300,1800,20):\n",
        "#     for i in np.random.randint(train_data.index):  #need correction!!!\n",
        "    for _ in range(5):\n",
        "        i = np.random.randint(train_data.index.values.shape[0]-DAYS_PRED*2)  #need correction!!!  \n",
        "#         i=900 #for overfiting traingin\n",
        "        batch_test_1, batch_test_2, batch_true = test_batch_ri_from_train_data(train_data, r_i=i) \n",
        "        prediction=f28_days_prediction(model,batch_test_1,batch_test_2)\n",
        "        y.append(rmsse(np.reshape(batch_true,28),prediction, display))\n",
        "        summation.append(sum_delta(np.reshape(batch_true,28),prediction))   \n",
        "    if display_figure:    \n",
        "        fig = go.Figure()\n",
        "        x = np.arange(len(y),len(prediction)+DAYS_PRED)\n",
        "        fig.add_trace(go.Scatter(x=x, y=y, name ='tatata'))\n",
        "        fig.show()\n",
        "    if display:    \n",
        "        print(f\" summation: {sum(summation)}\")\n",
        "        print(f\" RMSE: {sum(y)}\")\n",
        "    return sum(summation), sum(y)\n",
        "   \n",
        "#need correction!!!   \n",
        "def optimization(model, batch_1,batch_2,display=False): \n",
        "    fun_value=np.empty(shape=[1,],dtype = float)\n",
        "    for i in range(0,21):                         #need correction!!!\n",
        "        batch_2[0,27,0]=i\n",
        "        fun_value=np.append(fun_value,model([batch_1.astype(float), batch_2.astype(float)]).numpy())        \n",
        "    fun_value=np.delete(fun_value,0,axis=0)\n",
        "    i_min=np.argmin(fun_value)\n",
        "    if display:\n",
        "        print(f\" function values: {fun_value} \\n \\\n",
        "        min index (or index + 1 element): {i_min}  \\n \\\n",
        "        function min value: {fun_value[i_min]}\")    \n",
        "    return fun_value[i_min], i_min\n",
        "# _ , i_min  = optimization(model,batch_1,batch_2,display=True)\n",
        "# print(i_min)\n",
        "\n",
        "def f28_days_prediction(model, batch_1,batch_2):\n",
        "    prediction=np.empty(shape=[1,],dtype = float)\n",
        "    for i in range(28):    \n",
        "        _ , new_prediction = optimization(model,batch_1,batch_2,display=False)\n",
        "        prediction=np.append(prediction, new_prediction)\n",
        "        batch_2[0,27,0]=new_prediction\n",
        "        batch_1 = np.copy(batch_2) \n",
        "        batch_2 = np.roll(batch_2,-1)    \n",
        "\n",
        "    prediction=np.delete(prediction,0,axis=0)\n",
        "    return prediction\n",
        "\n",
        "# prediction=f28_days_prediction(batch_1,batch_2)\n",
        "# print(prediction)\n",
        "# print(prediction.shape,type(prediction))\n",
        "# fig = go.Figure()\n",
        "# x = np.arange(len(prediction))\n",
        "# fig.add_trace(go.Scatter(x=x, y=prediction))\n",
        "# fig.show()\n",
        "\n",
        "def test_batch_ri_from_train_data(series, size=DAYS_PRED,r_i = DAYS_PRED):      \n",
        "    \n",
        "    left_non_zero_index=0\n",
        "#   right_index=series.shape[0]-2*size    \n",
        "    right_index=r_i\n",
        "    \n",
        "    while series.iloc[left_non_zero_index, 1]==0:\n",
        "        left_non_zero_index +=1\n",
        "        \n",
        "    if right_index<left_non_zero_index: right_index=left_non_zero_index   \n",
        "       \n",
        "    batch_1=series.iloc[r_i:(r_i+size),1]\n",
        "    batch_2=series.iloc[r_i:(r_i+size),1]\n",
        "    batch_true=series.iloc[(r_i+size+1):(r_i+1+size*2),1]\n",
        "    \n",
        "    batch_1 = tf.transpose(np.expand_dims(batch_1,axis=0))\n",
        "    batch_2 = tf.transpose(np.expand_dims(batch_2,axis=0))\n",
        "    batch_true = tf.transpose(np.expand_dims(batch_true,axis=0))\n",
        "    \n",
        "    batch_1 = np.expand_dims(batch_1,axis=0)\n",
        "    batch_2 = np.expand_dims(batch_2,axis=0)\n",
        "    batch_true = np.expand_dims(batch_true,axis=0)\n",
        "    \n",
        "    batch_2 = np.roll(batch_2,-1)\n",
        "    \n",
        "    return batch_1, batch_2, batch_true\n",
        "\n",
        "# batch_1, batch_2, batch_true = test_batch_ri_from_train_data(train_data, size=DAYS_PRED,r_i = DAYS_PRED) \n",
        "# print(batch_2)\n",
        "\n",
        "def rmsse(y_true, y_pred,display=False):\n",
        "    if display:\n",
        "        print(f\"y_true sum: {np.sum(y_true)}, y_pred sum: {np.sum(y_pred)}\")\n",
        "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "\n",
        "def sum_delta(y_true, y_pred):    \n",
        "    return abs(np.sum(y_true)-np.sum(y_pred))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "OCxFeopZC4Sa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Layer_MSE(layers.Layer):\n",
        "\n",
        "    def __init__(self, units=32):\n",
        "        super(Layer_MSE, self).__init__()\n",
        "        \n",
        "        \n",
        "    def call(self, input1, input2):\n",
        "#         print(input1.shape)\n",
        "        out=tf.math.add(input1,-input2)\n",
        "#         print(f\"delta:{out}\")\n",
        "        out=out*out\n",
        "#         print(f\"out*out:{out}\")\n",
        "        out=tf.math.reduce_sum(out,axis=2)\n",
        "#         print(f\"reduce_sum:{out}\")\n",
        "        out = tf.math.sqrt(out)  \n",
        "#       print(out)\n",
        "        return out\n",
        "\n",
        "# x1 = tf.constant([[[1.0, 1.0], [1.0, 1.0]],\n",
        "#                    [[1.0, 1.0], [1.0, 1.0]],\n",
        "#                    [[1.0, 1.0], [1.0, 1.0]]])\n",
        "# x2 =  tf.constant([[[1.0, 2.0], [3.0, 4.0]],\n",
        "#                    [[1.0, 2.0], [3.0, 4.0]],\n",
        "#                    [[1.0, 2.0], [3.0, 4.0]]])\n",
        "# print(x1.shape)\n",
        "\n",
        "# test_layer = Layer_MSE()\n",
        "# y = test_layer(x1,x2)\n",
        "# print(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "xuFiCoVWC4Sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# tf.keras.losses.Reduction.NONE\n",
        "\n",
        "def grad(model, inputs, targets):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss_value = myloss(model, inputs, targets, training=True) # True or False?\n",
        "#         print(f\"loss_value in grad fucntion: {loss_value}\")\n",
        "    return loss_value, tape.gradient(loss_value, model.trainable_variables)\n",
        "\n",
        "def training_loop(model):\n",
        "    # Note: Rerunning this cell uses the same model variables\n",
        "    global TRAIN_STAGE\n",
        "    global BATCH_SIZE\n",
        "\n",
        "    # Keep results for plotting\n",
        "    train_loss_results = []\n",
        "    train_accuracy_results = []\n",
        "    \n",
        "    optimizer = tf.keras.optimizers.Adam()\n",
        "    print(optimizer)\n",
        "    shift_for_train_stage=0\n",
        "    for epoch in range(NUM_EPOCH):\n",
        "        epoch_loss_avg = tf.keras.metrics.Mean()\n",
        "        epoch_accuracy = tf.keras.metrics.Accuracy()\n",
        "\n",
        "      # Training loop - using batches of 32        \n",
        "#       for x,y in [[x_train, y_train]]:\n",
        "        for _ in range(BATCH_SIZE):\n",
        "            i=np.random.randint(len(y_train))            \n",
        "            x = [np.expand_dims(x_train[0][i],axis=0), np.expand_dims(x_train[0][1],axis=0)]\n",
        "            y = np.expand_dims(y_train[i],axis=0)\n",
        "            \n",
        "        # Optimize the model\n",
        "            loss_value, grads = grad(model, x, y)\n",
        "#             print(f\"y value in training loop : {x}\")\n",
        "#             print(f\"grads value in training loop : {grads}\")\n",
        "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "            # Track progress\n",
        "            epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
        "            # Compare predicted label to actual label\n",
        "            # training=True is needed only if there are layers with different\n",
        "            # behavior during training versus inference (e.g. Dropout).\n",
        "            epoch_accuracy.update_state(y, model(x, training=True))\n",
        "\n",
        "        # End epoch\n",
        "        train_loss_results.append(epoch_loss_avg.result())\n",
        "        train_accuracy_results.append(epoch_accuracy.result())\n",
        "\n",
        "        #Save the model\n",
        "        if (epoch % 10) == 0:\n",
        "          save_path = r'/content/Saved models'\n",
        "          name_of_file =\"SIA_model_v12\"\n",
        "          complete_path = os.path.join(save_path,name_of_file)\n",
        "          model.save(complete_path)\n",
        "          print(\"Model Saved\")\n",
        "\n",
        "        print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}, TRAIN_STAGE: {}\".format(epoch,\n",
        "                                                                    epoch_loss_avg.result(),\n",
        "                                                                    epoch_accuracy.result(),\n",
        "                                                                    TRAIN_STAGE))\n",
        "        if (epoch-shift_for_train_stage)>10 and np.all(np.array(train_loss_results)[-10:]<=EARLY_STOP_LOSS_VALUE):\n",
        "           print(f\"------ New TRAIN_STAGE---------\")\n",
        "           TRAIN_STAGE +=1\n",
        "           shift_for_train_stage=epoch\n",
        "          #  BATCH_SIZE = 2\n",
        "          #  optimizer = tf.keras.optimizers.Adadelta(learning_rate=0.1)\n",
        "           optimizer = tf.keras.optimizers.Adam()\n",
        "           print(optimizer)\n",
        "          \n",
        "\n",
        "        if TRAIN_STAGE == 3:\n",
        "            break\n",
        "       \n",
        "#         if epoch % 50 == 0:\n",
        "#             print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
        "#                                                                     epoch_loss_avg.result(),\n",
        "#                                                                     epoch_accuracy.result()))\n",
        "\n",
        "\n",
        "# optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# loss_value, grads = grad(model, features, labels)\n",
        "\n",
        "# print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "#                                           loss_value.numpy()))\n",
        "\n",
        "# optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "# print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
        "#                                           loss(model, features, labels, training=True).numpy()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8HUOyJdGt_L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model2=create_model(\"test model\")\n",
        "# model2.summary()\n",
        "# keras.utils.plot_model(model2,show_shapes=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "k2KI_cP9C4Sl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(model_name=''):\n",
        "    inputs_1 = keras.Input(shape=(DAYS_PRED,1))\n",
        "    inputs_2 = keras.Input(shape=(DAYS_PRED,1))\n",
        "#     BN = layers.BatchNormalization()\n",
        "#     x_1 = BN(inputs_1)\n",
        "#     x_2 = BN(inputs_2)    \n",
        "    convlayer = layers.Conv1D(NUM_FILTERS_IN_CONV_LAYER,\n",
        "                              KERNEL_SIZE,\n",
        "                              padding='valid',\n",
        "                              activation='sigmoid',\n",
        "                              kernel_initializer=tf.random_uniform_initializer(0,1,seed=70)\n",
        "                             )\n",
        "#     x_1 = convlayer(x_1)\n",
        "#     x_2 = convlayer(x_2)  \n",
        "    x_1 = convlayer(inputs_1)\n",
        "    x_2 = convlayer(inputs_2)\n",
        "    x_1 = layers.AveragePooling1D(pool_size=DAYS_PRED-KERNEL_SIZE+1)(x_1)\n",
        "    x_2 = layers.AveragePooling1D(pool_size=DAYS_PRED-KERNEL_SIZE+1)(x_2)\n",
        "    out=Layer_MSE()(x_1,x_2)  \n",
        "#     out=layers.Reshape(())(out)\n",
        "   \n",
        "    model = keras.Model([inputs_1,inputs_2], [out], name=model_name)\n",
        "        \n",
        "    return model\n",
        " \n",
        "def train_model():\n",
        "    \n",
        "    model = create_model()\n",
        "    keras.utils.plot_model(model,show_shapes=True)\n",
        "    \n",
        "#   loss_fn = tf.keras.losses.MeanAbsoluteError()\n",
        "    loss_fn = tf.keras.losses.MeanAbsoluteError(reduction=tf.keras.losses.Reduction.NONE)\n",
        "        \n",
        "    training_loop(model)\n",
        "    \n",
        "#     model.compile(optimizer='adam',\n",
        "#                 loss=Myloss,\n",
        "#                 metrics=['accuracy'])\n",
        "    \n",
        "#     print('# Fit model on training data')\n",
        "#     history=model.fit(x=x_train, \n",
        "#             y=y_train, \n",
        "#             epochs=30)\n",
        "    \n",
        "#     print('\\nhistory dict:', history.history)\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "eZEQyegoC4Sp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model2=create_model()\n",
        "#SAVE the model\n",
        "# save_path = r'/content/Saved models'\n",
        "# name_of_file =\"SIA_model_v12\"\n",
        "# complete_path = os.path.join(save_path,name_of_file)\n",
        "# model2.save(complete_path)\n",
        "\n",
        "#Load the model\n",
        "# new_model = tf.keras.models.load_model('/content/Saved models/SIA_model_v12')\n",
        "# print(new_model.trainable_variables)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "title": "[code]",
        "trusted": true,
        "id": "J_t8YVRDC4Ss",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sales, prices, calendar, submission = read_data()\n",
        "# NUM_ITEMS = sales.shape[0]  # 30490\n",
        "# DAYS_PRED = submission.shape[1] - 1  # 28\n",
        "\n",
        "# Glogbal Parameters\n",
        "NUM_ITEMS =  30490\n",
        "DAYS_PRED =  28\n",
        "\n",
        "# Global tuning variables\n",
        "NUM_FILTERS_IN_CONV_LAYER=7\n",
        "KERNEL_SIZE=14\n",
        "NUM_EPOCH = 3000\n",
        "BATCH_SIZE = 10\n",
        "NUM_SAMPLES = 1000\n",
        "EARLY_STOP_LOSS_VALUE=1\n",
        "\n",
        "TRAIN_STAGE=0\n",
        "\n",
        "def myloss(model, x, y, training):\n",
        "  # training=training is needed only if there are layers with different\n",
        "  # behavior during training versus inference (e.g. Dropout).\n",
        "  # y_ = model(x, training=training)\n",
        "        \n",
        "    if TRAIN_STAGE == -1:\n",
        "      y_ = model(x, training=True)\n",
        "      RMSE=0\n",
        "      summation=0\n",
        "      return abs(y_)*10e2\n",
        "    else:\n",
        "      y_ = model(x, training=True)  \n",
        "      summation, RMSE = validation(model)\n",
        "      print(f\"in myloss function: summation {summation}, RMSE: {RMSE}, TRAIN_STAGE: {TRAIN_STAGE}\")\n",
        "      return RMSE*10+abs(y_)\n",
        "\n",
        "    \n",
        "#     print(model.trainable_variables)     \n",
        "#     print(f\"y_ value in myloss function: {y_}, shape: {y_.shape}\")\n",
        "#     print(f\"y value in myloss function: {y}, shape: {y.shape} \")\n",
        "#     print(f\"tf.reduce_mean(y_) value in myloss function: {tf.reduce_mean(y_)} \")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "2fsA-bpyC4Sw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67ec93fd-266b-4c49-c048-16b3c3192a4a"
      },
      "source": [
        "# START CALCULATION\n",
        "input_1=np.empty(shape=[1,28,1],dtype = float)\n",
        "input_2=np.empty(shape=[1,28,1],dtype = float)\n",
        "for i in range(NUM_SAMPLES):\n",
        "    batch_1, batch_2, _ = generate_random_batch(train_data)\n",
        "#     batch_1, _, _ = generate_random_batch(train_data)\n",
        "#     _, batch_2, _ = generate_random_batch(train_data)\n",
        "    batch_1 = tf.transpose(np.expand_dims(batch_1,axis=0))\n",
        "    batch_2 = tf.transpose(np.expand_dims(batch_2,axis=0))\n",
        "    batch_1 = np.expand_dims(batch_1,axis=0)\n",
        "    batch_2 = np.expand_dims(batch_2,axis=0)   \n",
        "    input_1=np.append(input_1,batch_1,axis=0)\n",
        "    input_2=np.append(input_2,batch_2,axis=0)\n",
        "\n",
        "input_1=np.delete(input_1,0,axis=0)\n",
        "input_2=np.delete(input_2,0,axis=0)\n",
        "\n",
        "y_train=pd.Series(np.zeros(NUM_SAMPLES),dtype = float)\n",
        "x_train = [input_1, input_2]\n",
        "\n",
        "# print(f\"y_train value in start : {y_train}\")\n",
        "\n",
        "# x_val=x_train\n",
        "# y_val=y_train\n",
        "\n",
        "TRAIN_STAGE=1\n",
        "model=train_model()\n",
        "keras.utils.plot_model(model,show_shapes=True)\n",
        "# batch_1.shape\n",
        "# model.evaluate([batch_1,batch_2])\n",
        "\n",
        "# test1_model=create_model(\"test1 model\")\n",
        "# test1_model.summary()\n",
        "# keras.utils.plot_model(test1_model,show_shapes=True)\n",
        "\n",
        "Audio(filename=\"/content/Sounds/ring_end.mp3\", autoplay=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<tensorflow.python.keras.optimizer_v2.adam.Adam object at 0x7f1f71209ac8>\n",
            "in myloss function: summation 73.0, RMSE: 11.60626658488859, TRAIN_STAGE: 1\n",
            "in myloss function: summation 128.0, RMSE: 17.6729429593413, TRAIN_STAGE: 1\n",
            "in myloss function: summation 103.0, RMSE: 16.735141708507367, TRAIN_STAGE: 1\n",
            "in myloss function: summation 139.0, RMSE: 19.034729630958758, TRAIN_STAGE: 1\n",
            "in myloss function: summation 131.0, RMSE: 19.636204567463015, TRAIN_STAGE: 1\n",
            "in myloss function: summation 158.0, RMSE: 20.474174307781098, TRAIN_STAGE: 1\n",
            "in myloss function: summation 97.0, RMSE: 12.31214418670239, TRAIN_STAGE: 1\n",
            "in myloss function: summation 86.0, RMSE: 14.809473678416252, TRAIN_STAGE: 1\n",
            "in myloss function: summation 116.0, RMSE: 17.693759389403102, TRAIN_STAGE: 1\n",
            "in myloss function: summation 103.0, RMSE: 15.88377923141715, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 000: Loss: 165.930, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 102.0, RMSE: 15.116157722754949, TRAIN_STAGE: 1\n",
            "in myloss function: summation 124.0, RMSE: 17.560615959204316, TRAIN_STAGE: 1\n",
            "in myloss function: summation 95.0, RMSE: 14.40763173252316, TRAIN_STAGE: 1\n",
            "in myloss function: summation 149.0, RMSE: 20.54521730478131, TRAIN_STAGE: 1\n",
            "in myloss function: summation 128.0, RMSE: 17.772920597762948, TRAIN_STAGE: 1\n",
            "in myloss function: summation 143.0, RMSE: 18.982712127557416, TRAIN_STAGE: 1\n",
            "in myloss function: summation 120.0, RMSE: 16.865416420361555, TRAIN_STAGE: 1\n",
            "in myloss function: summation 115.0, RMSE: 14.869762836119794, TRAIN_STAGE: 1\n",
            "in myloss function: summation 98.0, RMSE: 13.469107980104987, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 11.528232271042498, TRAIN_STAGE: 1\n",
            "Epoch 001: Loss: 161.169, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 133.0, RMSE: 19.175825777801172, TRAIN_STAGE: 1\n",
            "in myloss function: summation 125.0, RMSE: 16.196369465401965, TRAIN_STAGE: 1\n",
            "in myloss function: summation 138.0, RMSE: 18.701438472141714, TRAIN_STAGE: 1\n",
            "in myloss function: summation 86.0, RMSE: 13.823028829464148, TRAIN_STAGE: 1\n",
            "in myloss function: summation 165.0, RMSE: 22.176836243017448, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 11.754863981453472, TRAIN_STAGE: 1\n",
            "in myloss function: summation 160.0, RMSE: 19.665211571412406, TRAIN_STAGE: 1\n",
            "in myloss function: summation 114.0, RMSE: 15.183762371509324, TRAIN_STAGE: 1\n",
            "in myloss function: summation 89.0, RMSE: 14.59397573413817, TRAIN_STAGE: 1\n",
            "in myloss function: summation 140.0, RMSE: 19.226111840270615, TRAIN_STAGE: 1\n",
            "Epoch 002: Loss: 170.565, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 165.0, RMSE: 19.272481669589595, TRAIN_STAGE: 1\n",
            "in myloss function: summation 74.0, RMSE: 14.142114423169513, TRAIN_STAGE: 1\n",
            "in myloss function: summation 107.0, RMSE: 15.108529897510369, TRAIN_STAGE: 1\n",
            "in myloss function: summation 147.0, RMSE: 18.793452238059324, TRAIN_STAGE: 1\n",
            "in myloss function: summation 139.0, RMSE: 20.38359279647695, TRAIN_STAGE: 1\n",
            "in myloss function: summation 109.0, RMSE: 16.378003106261257, TRAIN_STAGE: 1\n",
            "in myloss function: summation 163.0, RMSE: 20.99504697853053, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 13.484966938273088, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 11.29236109753057, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 10.8027730531056, TRAIN_STAGE: 1\n",
            "Epoch 003: Loss: 160.719, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 131.0, RMSE: 17.26376010886132, TRAIN_STAGE: 1\n",
            "in myloss function: summation 102.0, RMSE: 13.035790003971673, TRAIN_STAGE: 1\n",
            "in myloss function: summation 157.0, RMSE: 19.986699591187076, TRAIN_STAGE: 1\n",
            "in myloss function: summation 127.0, RMSE: 18.270541950862615, TRAIN_STAGE: 1\n",
            "in myloss function: summation 144.0, RMSE: 21.10989279939163, TRAIN_STAGE: 1\n",
            "in myloss function: summation 99.0, RMSE: 16.212220990345834, TRAIN_STAGE: 1\n",
            "in myloss function: summation 85.0, RMSE: 13.983260694668552, TRAIN_STAGE: 1\n",
            "in myloss function: summation 115.0, RMSE: 17.525660722757824, TRAIN_STAGE: 1\n",
            "in myloss function: summation 92.0, RMSE: 13.683994392099715, TRAIN_STAGE: 1\n",
            "in myloss function: summation 122.0, RMSE: 18.84797117222255, TRAIN_STAGE: 1\n",
            "Epoch 004: Loss: 169.988, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 11.364366471688028, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 12.825929155403403, TRAIN_STAGE: 1\n",
            "in myloss function: summation 141.0, RMSE: 21.60216799704683, TRAIN_STAGE: 1\n",
            "in myloss function: summation 142.0, RMSE: 19.916845880344784, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.274153804558757, TRAIN_STAGE: 1\n",
            "in myloss function: summation 77.0, RMSE: 12.549579134488756, TRAIN_STAGE: 1\n",
            "in myloss function: summation 140.0, RMSE: 18.658110124120412, TRAIN_STAGE: 1\n",
            "in myloss function: summation 120.0, RMSE: 18.0467436569413, TRAIN_STAGE: 1\n",
            "in myloss function: summation 165.0, RMSE: 19.70826766184528, TRAIN_STAGE: 1\n",
            "in myloss function: summation 131.0, RMSE: 15.95052767228644, TRAIN_STAGE: 1\n",
            "Epoch 005: Loss: 159.950, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 61.0, RMSE: 9.514085171991209, TRAIN_STAGE: 1\n",
            "in myloss function: summation 108.0, RMSE: 16.50622047978733, TRAIN_STAGE: 1\n",
            "in myloss function: summation 168.0, RMSE: 21.256911771389426, TRAIN_STAGE: 1\n",
            "in myloss function: summation 81.0, RMSE: 15.126599614239476, TRAIN_STAGE: 1\n",
            "in myloss function: summation 103.0, RMSE: 17.3441679448259, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 12.805812503898451, TRAIN_STAGE: 1\n",
            "in myloss function: summation 107.0, RMSE: 15.764571872553411, TRAIN_STAGE: 1\n",
            "in myloss function: summation 139.0, RMSE: 17.76715341212587, TRAIN_STAGE: 1\n",
            "in myloss function: summation 99.0, RMSE: 13.766346203515237, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 11.669463207426867, TRAIN_STAGE: 1\n",
            "Epoch 006: Loss: 151.607, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 120.0, RMSE: 18.09805292695487, TRAIN_STAGE: 1\n",
            "in myloss function: summation 126.0, RMSE: 16.84661963785984, TRAIN_STAGE: 1\n",
            "in myloss function: summation 76.0, RMSE: 14.02000967250127, TRAIN_STAGE: 1\n",
            "in myloss function: summation 117.0, RMSE: 16.758526491840463, TRAIN_STAGE: 1\n",
            "in myloss function: summation 119.0, RMSE: 16.148732962010435, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 12.171414269851114, TRAIN_STAGE: 1\n",
            "in myloss function: summation 85.0, RMSE: 12.18279836686272, TRAIN_STAGE: 1\n",
            "in myloss function: summation 151.0, RMSE: 19.70081485641264, TRAIN_STAGE: 1\n",
            "in myloss function: summation 111.0, RMSE: 15.761541524436677, TRAIN_STAGE: 1\n",
            "in myloss function: summation 77.0, RMSE: 12.984175794875577, TRAIN_STAGE: 1\n",
            "Epoch 007: Loss: 154.721, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 11.76483249427368, TRAIN_STAGE: 1\n",
            "in myloss function: summation 146.0, RMSE: 19.048551927837188, TRAIN_STAGE: 1\n",
            "in myloss function: summation 104.0, RMSE: 16.426891808253142, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 16.19409673239859, TRAIN_STAGE: 1\n",
            "in myloss function: summation 166.0, RMSE: 20.04956145989953, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 8.874913738372214, TRAIN_STAGE: 1\n",
            "in myloss function: summation 74.0, RMSE: 11.450733637293737, TRAIN_STAGE: 1\n",
            "in myloss function: summation 113.0, RMSE: 18.326335306199823, TRAIN_STAGE: 1\n",
            "in myloss function: summation 85.0, RMSE: 16.496642537964128, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 10.47312046880902, TRAIN_STAGE: 1\n",
            "Epoch 008: Loss: 149.153, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 12.402750389540317, TRAIN_STAGE: 1\n",
            "in myloss function: summation 94.0, RMSE: 14.215707635371224, TRAIN_STAGE: 1\n",
            "in myloss function: summation 143.0, RMSE: 18.944556488858346, TRAIN_STAGE: 1\n",
            "in myloss function: summation 106.0, RMSE: 16.459508038113583, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 14.656830057947198, TRAIN_STAGE: 1\n",
            "in myloss function: summation 146.0, RMSE: 18.641448659657865, TRAIN_STAGE: 1\n",
            "in myloss function: summation 87.0, RMSE: 15.097323039698969, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 10.577330154693081, TRAIN_STAGE: 1\n",
            "in myloss function: summation 79.0, RMSE: 10.346974025749505, TRAIN_STAGE: 1\n",
            "in myloss function: summation 153.0, RMSE: 21.035200509381, TRAIN_STAGE: 1\n",
            "Epoch 009: Loss: 152.463, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 14.198761567357916, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 9.395197817263472, TRAIN_STAGE: 1\n",
            "in myloss function: summation 100.0, RMSE: 16.42784914294588, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 11.734704089057997, TRAIN_STAGE: 1\n",
            "in myloss function: summation 138.0, RMSE: 16.920173309012633, TRAIN_STAGE: 1\n",
            "in myloss function: summation 148.0, RMSE: 19.757454730565392, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 11.323650071811748, TRAIN_STAGE: 1\n",
            "in myloss function: summation 144.0, RMSE: 19.84571953126616, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 7.151844186067909, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 10.633144534405316, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 010: Loss: 137.454, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 9.668045438305489, TRAIN_STAGE: 1\n",
            "in myloss function: summation 115.0, RMSE: 16.679344945385168, TRAIN_STAGE: 1\n",
            "in myloss function: summation 101.0, RMSE: 15.671020042352625, TRAIN_STAGE: 1\n",
            "in myloss function: summation 100.0, RMSE: 14.397311984332935, TRAIN_STAGE: 1\n",
            "in myloss function: summation 82.0, RMSE: 13.020490692487652, TRAIN_STAGE: 1\n",
            "in myloss function: summation 82.0, RMSE: 14.159388613003978, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 11.277310924976899, TRAIN_STAGE: 1\n",
            "in myloss function: summation 142.0, RMSE: 20.685955287191334, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 12.280063322247614, TRAIN_STAGE: 1\n",
            "in myloss function: summation 121.0, RMSE: 19.860698542351315, TRAIN_STAGE: 1\n",
            "Epoch 011: Loss: 147.733, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.689416826171094, TRAIN_STAGE: 1\n",
            "in myloss function: summation 100.0, RMSE: 14.695022315354926, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 12.240427853972195, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 9.386704875482437, TRAIN_STAGE: 1\n",
            "in myloss function: summation 124.0, RMSE: 21.079907543452958, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.840641087463798, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 10.189809142508022, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 10.592033240864241, TRAIN_STAGE: 1\n",
            "in myloss function: summation 79.0, RMSE: 13.885153303147806, TRAIN_STAGE: 1\n",
            "in myloss function: summation 77.0, RMSE: 13.653498307835209, TRAIN_STAGE: 1\n",
            "Epoch 012: Loss: 128.311, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 15.03702524355297, TRAIN_STAGE: 1\n",
            "in myloss function: summation 87.0, RMSE: 12.58053156122134, TRAIN_STAGE: 1\n",
            "in myloss function: summation 145.0, RMSE: 19.92003611610006, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 8.750509001967297, TRAIN_STAGE: 1\n",
            "in myloss function: summation 103.0, RMSE: 18.014845983678192, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 9.488616893910946, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 10.887202273267537, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 11.363530532866566, TRAIN_STAGE: 1\n",
            "in myloss function: summation 81.0, RMSE: 12.259056297163283, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 14.667835654199324, TRAIN_STAGE: 1\n",
            "Epoch 013: Loss: 133.017, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 91.0, RMSE: 16.375801828544382, TRAIN_STAGE: 1\n",
            "in myloss function: summation 143.0, RMSE: 21.183378312324198, TRAIN_STAGE: 1\n",
            "in myloss function: summation 24.0, RMSE: 5.9925607786336865, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 12.687476645362059, TRAIN_STAGE: 1\n",
            "in myloss function: summation 83.0, RMSE: 13.540565334794522, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 9.0064702004364, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 8.820876300730792, TRAIN_STAGE: 1\n",
            "in myloss function: summation 147.0, RMSE: 17.626926198905824, TRAIN_STAGE: 1\n",
            "in myloss function: summation 77.0, RMSE: 10.854062171550416, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 10.900343292737535, TRAIN_STAGE: 1\n",
            "Epoch 014: Loss: 127.070, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 10.425690584425016, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 10.378209486953516, TRAIN_STAGE: 1\n",
            "in myloss function: summation 116.0, RMSE: 16.594072304590362, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 11.672858783423928, TRAIN_STAGE: 1\n",
            "in myloss function: summation 95.0, RMSE: 13.728212928697419, TRAIN_STAGE: 1\n",
            "in myloss function: summation 148.0, RMSE: 19.362518595229712, TRAIN_STAGE: 1\n",
            "in myloss function: summation 111.0, RMSE: 16.569757917598956, TRAIN_STAGE: 1\n",
            "in myloss function: summation 101.0, RMSE: 12.358651086168512, TRAIN_STAGE: 1\n",
            "in myloss function: summation 89.0, RMSE: 14.67020232112932, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 11.346939928744394, TRAIN_STAGE: 1\n",
            "Epoch 015: Loss: 137.153, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 18.0, RMSE: 6.0478832696127744, TRAIN_STAGE: 1\n",
            "in myloss function: summation 135.0, RMSE: 19.232328526841517, TRAIN_STAGE: 1\n",
            "in myloss function: summation 19.0, RMSE: 6.962941533493225, TRAIN_STAGE: 1\n",
            "in myloss function: summation 91.0, RMSE: 14.202691693647273, TRAIN_STAGE: 1\n",
            "in myloss function: summation 91.0, RMSE: 14.77341105165773, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 8.314586232625839, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 10.292225491460469, TRAIN_STAGE: 1\n",
            "in myloss function: summation 104.0, RMSE: 13.601055539231444, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 8.38708351007167, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 9.03237626302749, TRAIN_STAGE: 1\n",
            "Epoch 016: Loss: 110.901, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 6.083713360991921, TRAIN_STAGE: 1\n",
            "in myloss function: summation 134.0, RMSE: 16.82168654457931, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 13.268792624101767, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 10.265453950902465, TRAIN_STAGE: 1\n",
            "in myloss function: summation 140.0, RMSE: 20.13361820145843, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 8.592859597029223, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 11.069256846443844, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 9.394890297173053, TRAIN_STAGE: 1\n",
            "in myloss function: summation 81.0, RMSE: 11.852314086612708, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 10.558973568574736, TRAIN_STAGE: 1\n",
            "Epoch 017: Loss: 118.082, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 8.557087918578675, TRAIN_STAGE: 1\n",
            "in myloss function: summation 114.0, RMSE: 18.055344294258507, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 7.753724491398472, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 8.685729845581063, TRAIN_STAGE: 1\n",
            "in myloss function: summation 88.0, RMSE: 14.607757678939981, TRAIN_STAGE: 1\n",
            "in myloss function: summation 80.0, RMSE: 14.529354491420985, TRAIN_STAGE: 1\n",
            "in myloss function: summation 84.0, RMSE: 12.90128765917866, TRAIN_STAGE: 1\n",
            "in myloss function: summation 89.0, RMSE: 15.376639373781419, TRAIN_STAGE: 1\n",
            "in myloss function: summation 106.0, RMSE: 15.8630977670531, TRAIN_STAGE: 1\n",
            "in myloss function: summation 86.0, RMSE: 14.836801656768776, TRAIN_STAGE: 1\n",
            "Epoch 018: Loss: 131.233, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 80.0, RMSE: 13.03592385556778, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.315208917187286, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 9.499473254142648, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 8.871418527197697, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 13.52846507960198, TRAIN_STAGE: 1\n",
            "in myloss function: summation 61.0, RMSE: 10.937244594554766, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 11.293420184946516, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 9.546631627398119, TRAIN_STAGE: 1\n",
            "in myloss function: summation 87.0, RMSE: 14.609783984384471, TRAIN_STAGE: 1\n",
            "in myloss function: summation 85.0, RMSE: 14.301466507261152, TRAIN_STAGE: 1\n",
            "Epoch 019: Loss: 114.973, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 130.0, RMSE: 18.125008272521544, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 13.626843756826322, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 10.161612376709796, TRAIN_STAGE: 1\n",
            "in myloss function: summation 83.0, RMSE: 16.27472042921, TRAIN_STAGE: 1\n",
            "in myloss function: summation 109.0, RMSE: 15.277827504290237, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 10.07447811893047, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 12.171480789393591, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 12.703695732687304, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 9.502878052404165, TRAIN_STAGE: 1\n",
            "in myloss function: summation 112.0, RMSE: 16.885019261288164, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 020: Loss: 134.853, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 12.697618884747179, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.105575678694574, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 10.608297776382994, TRAIN_STAGE: 1\n",
            "in myloss function: summation 80.0, RMSE: 12.647682300596983, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.114134804602095, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 7.312615203982101, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 12.292227952244158, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 12.503668470846689, TRAIN_STAGE: 1\n",
            "in myloss function: summation 109.0, RMSE: 15.209988618289415, TRAIN_STAGE: 1\n",
            "in myloss function: summation 13.0, RMSE: 6.389721710594335, TRAIN_STAGE: 1\n",
            "Epoch 021: Loss: 108.940, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 83.0, RMSE: 13.218434652752125, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 8.994139040696057, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 14.62866845021679, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 8.180529404845135, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 7.392382076938309, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 10.393337658259462, TRAIN_STAGE: 1\n",
            "in myloss function: summation 97.0, RMSE: 17.377313540579795, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 12.769663942917907, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 11.147703294030304, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.726099889918412, TRAIN_STAGE: 1\n",
            "Epoch 022: Loss: 116.867, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 7.693696914681246, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 11.653576602409757, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 12.08807638215679, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 12.956515472071874, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 12.12214016688931, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 11.9512113364916, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 9.596216859695836, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 11.320485593865032, TRAIN_STAGE: 1\n",
            "in myloss function: summation 74.0, RMSE: 10.962514877688285, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 8.960158162140495, TRAIN_STAGE: 1\n",
            "Epoch 023: Loss: 109.346, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 9.21115269211724, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 9.853300128277791, TRAIN_STAGE: 1\n",
            "in myloss function: summation 82.0, RMSE: 13.833389245150073, TRAIN_STAGE: 1\n",
            "in myloss function: summation 98.0, RMSE: 14.158941226121325, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 11.823950908352963, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 11.256505672474576, TRAIN_STAGE: 1\n",
            "in myloss function: summation 81.0, RMSE: 14.604017251790443, TRAIN_STAGE: 1\n",
            "in myloss function: summation 76.0, RMSE: 11.239446796341527, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 11.455958091715827, TRAIN_STAGE: 1\n",
            "in myloss function: summation 134.0, RMSE: 18.873477186189813, TRAIN_STAGE: 1\n",
            "Epoch 024: Loss: 126.346, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 60.0, RMSE: 12.932281587045287, TRAIN_STAGE: 1\n",
            "in myloss function: summation 13.0, RMSE: 6.81350002634253, TRAIN_STAGE: 1\n",
            "in myloss function: summation 80.0, RMSE: 14.560654495188729, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 10.011648780625286, TRAIN_STAGE: 1\n",
            "in myloss function: summation 108.0, RMSE: 14.4939242756101, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 9.632470768965149, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.932242691629575, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 12.134966515702562, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 14.445925248892554, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 7.880300996803474, TRAIN_STAGE: 1\n",
            "Epoch 025: Loss: 111.886, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 7.6827567134842845, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 13.663352445567678, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 13.509873571963183, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 10.258043503056248, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 9.519468331570481, TRAIN_STAGE: 1\n",
            "in myloss function: summation 74.0, RMSE: 10.531588197083952, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 9.408482796141458, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 13.390298558946053, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 11.097729095307363, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 7.437994526960635, TRAIN_STAGE: 1\n",
            "Epoch 026: Loss: 106.536, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 10.335794794839913, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 10.939470225331359, TRAIN_STAGE: 1\n",
            "in myloss function: summation 84.0, RMSE: 14.167038357398186, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 9.074740657945894, TRAIN_STAGE: 1\n",
            "in myloss function: summation 81.0, RMSE: 14.916501720352677, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 12.906498388555196, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 8.829510484278224, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 8.414319474357915, TRAIN_STAGE: 1\n",
            "in myloss function: summation 79.0, RMSE: 13.904410353923833, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 13.321265120720756, TRAIN_STAGE: 1\n",
            "Epoch 027: Loss: 116.840, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 20.0, RMSE: 7.063222611544674, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 11.895005116543018, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 13.688273061924153, TRAIN_STAGE: 1\n",
            "in myloss function: summation 103.0, RMSE: 16.781636409736244, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 7.590660253193734, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 10.433714975018907, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 9.283281278379702, TRAIN_STAGE: 1\n",
            "in myloss function: summation 99.0, RMSE: 16.392519859206764, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 8.539751377522693, TRAIN_STAGE: 1\n",
            "in myloss function: summation 96.0, RMSE: 13.987983438190685, TRAIN_STAGE: 1\n",
            "Epoch 028: Loss: 115.706, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.531619163045612, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 11.133128027668665, TRAIN_STAGE: 1\n",
            "in myloss function: summation 84.0, RMSE: 13.199994243134434, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 8.151579060749738, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 7.416948901991838, TRAIN_STAGE: 1\n",
            "in myloss function: summation 107.0, RMSE: 15.643298163080749, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 11.860367888449552, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 12.279425308406953, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 8.929858010439071, TRAIN_STAGE: 1\n",
            "in myloss function: summation 98.0, RMSE: 16.407476764220274, TRAIN_STAGE: 1\n",
            "Epoch 029: Loss: 117.605, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 9.544046921412992, TRAIN_STAGE: 1\n",
            "in myloss function: summation 86.0, RMSE: 14.520303830546558, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 13.282969108386572, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 8.874805694781918, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.594373226071802, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.156312830325838, TRAIN_STAGE: 1\n",
            "in myloss function: summation 88.0, RMSE: 17.59151546694413, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 11.739683794691754, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 11.1673976049311, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 11.267283496879196, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 030: Loss: 114.761, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 11.016586911736043, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 8.83679748408724, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 11.040562903604213, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 9.471590358543477, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 8.741652916041888, TRAIN_STAGE: 1\n",
            "in myloss function: summation 92.0, RMSE: 11.564463920893145, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.547802313018376, TRAIN_STAGE: 1\n",
            "in myloss function: summation 96.0, RMSE: 17.544858055915928, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 8.81997334031683, TRAIN_STAGE: 1\n",
            "in myloss function: summation 109.0, RMSE: 15.245852275554698, TRAIN_STAGE: 1\n",
            "Epoch 031: Loss: 111.892, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 10.71268566601917, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 11.037996571149353, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 13.182855763191087, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 10.584170519441548, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 10.208863748849645, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 12.267353629012563, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 11.919926536012836, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 11.411769426764101, TRAIN_STAGE: 1\n",
            "in myloss function: summation 80.0, RMSE: 14.340741714949532, TRAIN_STAGE: 1\n",
            "in myloss function: summation 82.0, RMSE: 13.624584583176272, TRAIN_STAGE: 1\n",
            "Epoch 032: Loss: 119.325, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 12.655317470757845, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 11.956587351752788, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.321047242160887, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 7.581920543431065, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 13.14296468220305, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 9.172075442660065, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 11.540072124843084, TRAIN_STAGE: 1\n",
            "in myloss function: summation 61.0, RMSE: 12.066730058110828, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 10.77372205970744, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 11.137572570959145, TRAIN_STAGE: 1\n",
            "Epoch 033: Loss: 109.389, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 61.0, RMSE: 11.43283034555079, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 7.207344963536516, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 9.224132889443084, TRAIN_STAGE: 1\n",
            "in myloss function: summation 133.0, RMSE: 16.082350003050564, TRAIN_STAGE: 1\n",
            "in myloss function: summation 74.0, RMSE: 12.496188279659517, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 12.936204669468845, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 9.476723946390909, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 13.995630833557271, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 9.849068690478948, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 12.94283813012546, TRAIN_STAGE: 1\n",
            "Epoch 034: Loss: 115.676, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 8.985494817800605, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 8.973571251613283, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 8.39182489579009, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 8.85377360324437, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 8.63968169386863, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 9.37409543047242, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 11.205018491770002, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 7.072790881073831, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 6.956339541321885, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 12.901151208858602, TRAIN_STAGE: 1\n",
            "Epoch 035: Loss: 91.380, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 9.906587638494733, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 6.7945070742701725, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 9.786057699374725, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 6.453285512632922, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 8.137513627089948, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 11.401744064261234, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 10.25254665741174, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 7.604465043519753, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 9.282027873651353, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 9.912844433953362, TRAIN_STAGE: 1\n",
            "Epoch 036: Loss: 89.556, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 91.0, RMSE: 12.880464999346973, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 11.498539206455357, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 9.221884880863366, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 12.256756052171372, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 8.981571102382418, TRAIN_STAGE: 1\n",
            "in myloss function: summation 79.0, RMSE: 13.585075949362192, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 10.930188566675596, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 11.760440158000268, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 9.017146581069834, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 11.88256995751688, TRAIN_STAGE: 1\n",
            "Epoch 037: Loss: 112.034, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 11.176338295309572, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 10.62964980437165, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 9.704444952558912, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 6.796127564798539, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 8.150802138863485, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 9.209678047381487, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 13.185966223136031, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 13.554382485077891, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 9.794482121238197, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 11.603083644985881, TRAIN_STAGE: 1\n",
            "Epoch 038: Loss: 103.832, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 12.932124830687517, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 10.908487669950024, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 11.26658449863914, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 7.911375416867502, TRAIN_STAGE: 1\n",
            "in myloss function: summation 26.0, RMSE: 7.626434804700266, TRAIN_STAGE: 1\n",
            "in myloss function: summation 84.0, RMSE: 14.718477444174045, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 12.36311512105626, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 7.676366880929068, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 8.626372032078093, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 8.68571255811205, TRAIN_STAGE: 1\n",
            "Epoch 039: Loss: 102.739, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 10.782161638994472, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 9.380330508810841, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 11.955692567137799, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 8.334723711552364, TRAIN_STAGE: 1\n",
            "in myloss function: summation 27.0, RMSE: 10.719708476929977, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 12.195879572119706, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 8.378177077275986, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 11.090484035211226, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 6.223997153574391, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 12.60442483471216, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 040: Loss: 101.692, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 8.057845156447668, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 8.656436471810263, TRAIN_STAGE: 1\n",
            "in myloss function: summation 90.0, RMSE: 12.608820493093903, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 13.67888495323529, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 13.606688885122821, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 7.893842821901335, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 6.131000593694821, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 7.584622925145583, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 10.982034833591802, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 10.351701373670851, TRAIN_STAGE: 1\n",
            "Epoch 041: Loss: 99.572, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 10.044517687073789, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 9.397288462340258, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 12.415959772189103, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 8.884656506827827, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 9.722936548067603, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 10.155597669895648, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 9.26640347639823, TRAIN_STAGE: 1\n",
            "in myloss function: summation 87.0, RMSE: 14.27944962465574, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 8.122411600994234, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 7.617575485066462, TRAIN_STAGE: 1\n",
            "Epoch 042: Loss: 99.943, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 24.0, RMSE: 6.937950602651016, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 7.031036827206071, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 6.822535854020111, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 7.708799133783598, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 13.93196929949772, TRAIN_STAGE: 1\n",
            "in myloss function: summation 14.0, RMSE: 6.329174480040796, TRAIN_STAGE: 1\n",
            "in myloss function: summation 19.0, RMSE: 7.208068455650995, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 11.849208685640221, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.232961094116899, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 8.253830785888145, TRAIN_STAGE: 1\n",
            "Epoch 043: Loss: 84.329, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 9.134355900555644, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 8.98141979101183, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 9.281178228554076, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 9.037779172739395, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 6.445290346350541, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 7.73754781443856, TRAIN_STAGE: 1\n",
            "in myloss function: summation 87.0, RMSE: 15.451239117250491, TRAIN_STAGE: 1\n",
            "in myloss function: summation 17.0, RMSE: 10.203697124961135, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.056693951914416, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 12.370828016685838, TRAIN_STAGE: 1\n",
            "Epoch 044: Loss: 95.723, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 106.0, RMSE: 16.79799297335388, TRAIN_STAGE: 1\n",
            "in myloss function: summation 78.0, RMSE: 11.90854689684054, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 10.117248921315689, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 10.675481378171687, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 8.748857096856371, TRAIN_STAGE: 1\n",
            "in myloss function: summation 27.0, RMSE: 7.853241758668491, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 12.016965069506796, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 11.195192034346642, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 10.205966302044281, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 8.507118888189975, TRAIN_STAGE: 1\n",
            "Epoch 045: Loss: 108.088, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 13.0, RMSE: 6.2986744651290625, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 11.668923477941012, TRAIN_STAGE: 1\n",
            "in myloss function: summation 12.0, RMSE: 7.028241164175355, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 10.731698030793172, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.31567962618293, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 9.445961414438056, TRAIN_STAGE: 1\n",
            "in myloss function: summation 77.0, RMSE: 12.836306418046313, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 13.752782228355287, TRAIN_STAGE: 1\n",
            "in myloss function: summation 12.0, RMSE: 6.191701183615287, TRAIN_STAGE: 1\n",
            "in myloss function: summation 108.0, RMSE: 16.224714876739228, TRAIN_STAGE: 1\n",
            "Epoch 046: Loss: 106.508, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 7.012636618184139, TRAIN_STAGE: 1\n",
            "in myloss function: summation 74.0, RMSE: 12.938858427378111, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 10.534188877648626, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 10.907631380627167, TRAIN_STAGE: 1\n",
            "in myloss function: summation 80.0, RMSE: 12.741998300628735, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 10.314035595428566, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 7.312616814725475, TRAIN_STAGE: 1\n",
            "in myloss function: summation 13.0, RMSE: 7.007242084114081, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 6.784789247115136, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 8.326663028490918, TRAIN_STAGE: 1\n",
            "Epoch 047: Loss: 93.903, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 7.272052311307105, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 11.561883748140596, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 10.839215238182705, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 9.378523972218025, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.734940813769745, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 9.136446058497768, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 6.209355393500203, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 9.541235466243092, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 12.007355231412157, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 7.566923365461715, TRAIN_STAGE: 1\n",
            "Epoch 048: Loss: 96.297, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 10.242907786414658, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.714094221341681, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 9.044802690015718, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 9.44584680686299, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 9.217847691941412, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 10.6786687256507, TRAIN_STAGE: 1\n",
            "in myloss function: summation 60.0, RMSE: 12.05240389437823, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 11.232886070668869, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 6.409991442083353, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 8.242801530080131, TRAIN_STAGE: 1\n",
            "Epoch 049: Loss: 94.316, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 9.976524266366487, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 12.409980294435664, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 8.662402586551867, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 11.53772061313175, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.294370220613887, TRAIN_STAGE: 1\n",
            "in myloss function: summation 18.0, RMSE: 8.178299506582084, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 7.7373987118384315, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.41522805797236, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 11.667027327719666, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 10.360793884610674, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 050: Loss: 96.252, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 82.0, RMSE: 10.424642129437055, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 9.796077723669052, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 5.9545489944313115, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 7.953963481781701, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 11.294729034387943, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 12.426590784599568, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 8.440104424699836, TRAIN_STAGE: 1\n",
            "in myloss function: summation 97.0, RMSE: 14.611157402407574, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 7.070433820489142, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 9.565789380322832, TRAIN_STAGE: 1\n",
            "Epoch 051: Loss: 97.568, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 9.156491019456855, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 11.86298273507452, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 13.971821245480637, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 8.973540152975488, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 7.1198703457695744, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 12.039198049315388, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 5.768167811407416, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 11.721861391524108, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 6.2653060205799065, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 8.489551956690738, TRAIN_STAGE: 1\n",
            "Epoch 052: Loss: 95.399, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 11.82991349429537, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 13.86140175158375, TRAIN_STAGE: 1\n",
            "in myloss function: summation 82.0, RMSE: 13.318272198707527, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 11.351445877104183, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 10.271633490645566, TRAIN_STAGE: 1\n",
            "in myloss function: summation 83.0, RMSE: 14.318709753757677, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 7.666426676373506, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 9.745630095185662, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 8.092262156926783, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 7.6600481785369325, TRAIN_STAGE: 1\n",
            "Epoch 053: Loss: 108.134, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 10.423860822196076, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 11.368132722067141, TRAIN_STAGE: 1\n",
            "in myloss function: summation 27.0, RMSE: 8.037154068130581, TRAIN_STAGE: 1\n",
            "in myloss function: summation 61.0, RMSE: 11.835793260671949, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 7.660596254588488, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 11.304389204434889, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.652767500092041, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 8.381692546067447, TRAIN_STAGE: 1\n",
            "in myloss function: summation 24.0, RMSE: 9.350182137786945, TRAIN_STAGE: 1\n",
            "in myloss function: summation 99.0, RMSE: 15.37525695984844, TRAIN_STAGE: 1\n",
            "Epoch 054: Loss: 106.411, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 9.99900673497522, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 11.324597533922686, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 9.21538580567537, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 9.379055355464006, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.702077132278317, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 9.032600508528226, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 10.01705287208574, TRAIN_STAGE: 1\n",
            "in myloss function: summation 26.0, RMSE: 7.902955463025835, TRAIN_STAGE: 1\n",
            "in myloss function: summation 80.0, RMSE: 12.535309520024555, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 10.026285007020284, TRAIN_STAGE: 1\n",
            "Epoch 055: Loss: 99.148, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 10.57529627768878, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 11.885423057950007, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 13.782619140444423, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 11.505750910324508, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 8.7900188794482, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 10.702331438794955, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 9.308479426974076, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 10.175578322208427, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 10.585199480817868, TRAIN_STAGE: 1\n",
            "in myloss function: summation 93.0, RMSE: 11.80459253876229, TRAIN_STAGE: 1\n",
            "Epoch 056: Loss: 109.146, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 79.0, RMSE: 13.713103749354431, TRAIN_STAGE: 1\n",
            "in myloss function: summation 26.0, RMSE: 6.263103408469754, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 10.226668587413744, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 7.790611678636658, TRAIN_STAGE: 1\n",
            "in myloss function: summation 20.0, RMSE: 8.38887930719199, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 11.622710210987757, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 7.8211261175993405, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 11.044350395825706, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 10.850653515365419, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 11.809200236117416, TRAIN_STAGE: 1\n",
            "Epoch 057: Loss: 99.546, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 10.938601541570481, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 8.44599963573873, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 9.78958425083657, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 7.9512181223001415, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 6.50794306851843, TRAIN_STAGE: 1\n",
            "in myloss function: summation 16.0, RMSE: 6.8906561442738985, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 12.307259976454947, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 10.413425615203197, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 8.897239156333963, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 9.18878556843641, TRAIN_STAGE: 1\n",
            "Epoch 058: Loss: 91.348, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 10.696892831577953, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 8.728958733061049, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 10.366954738140649, TRAIN_STAGE: 1\n",
            "in myloss function: summation 82.0, RMSE: 12.608178351357939, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 11.892929043495432, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 8.145295353193074, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 7.912296687581982, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 10.761661158663394, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.432148322055532, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 7.906524822151992, TRAIN_STAGE: 1\n",
            "Epoch 059: Loss: 97.471, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 24.0, RMSE: 7.645715604693641, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 7.479120654138171, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 11.409068830563676, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 10.550737941703346, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 10.8801865339546, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 9.52567590169791, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 8.571419029514997, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 9.623184901374707, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 13.80867544896436, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 7.865141753802462, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 060: Loss: 97.370, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 11.13417571559193, TRAIN_STAGE: 1\n",
            "in myloss function: summation 13.0, RMSE: 6.853017443372361, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 8.412869848967583, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 8.475610365021767, TRAIN_STAGE: 1\n",
            "in myloss function: summation 60.0, RMSE: 10.260924115211846, TRAIN_STAGE: 1\n",
            "in myloss function: summation 26.0, RMSE: 9.299045592078683, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 7.313687697441569, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.698025741354016, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 8.185495338808552, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 11.426694876651398, TRAIN_STAGE: 1\n",
            "Epoch 061: Loss: 91.076, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 9.467684967073623, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 11.719104837217476, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 8.695402609759936, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 10.519020943622788, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 9.877285104725987, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 7.810257387434147, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 8.283887841565718, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 11.300486370396253, TRAIN_STAGE: 1\n",
            "in myloss function: summation 26.0, RMSE: 9.64305321689327, TRAIN_STAGE: 1\n",
            "in myloss function: summation 15.0, RMSE: 7.901008046863833, TRAIN_STAGE: 1\n",
            "Epoch 062: Loss: 95.239, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 9.19577288981185, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 14.396957405460036, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 9.643544294913614, TRAIN_STAGE: 1\n",
            "in myloss function: summation 88.0, RMSE: 12.79358110613955, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 12.035046360175913, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 10.656942386811396, TRAIN_STAGE: 1\n",
            "in myloss function: summation 27.0, RMSE: 7.776311058770704, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 10.133250040588555, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 8.451061431407084, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 9.872304910505235, TRAIN_STAGE: 1\n",
            "Epoch 063: Loss: 104.978, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 10.005184489480959, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 8.596789342651252, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 12.138718826314106, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 10.470205252403298, TRAIN_STAGE: 1\n",
            "in myloss function: summation 60.0, RMSE: 13.994315255009841, TRAIN_STAGE: 1\n",
            "in myloss function: summation 18.0, RMSE: 7.017395384577393, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 11.10898686877533, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 10.591189578905961, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 11.22885615969123, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 12.64988505318388, TRAIN_STAGE: 1\n",
            "Epoch 064: Loss: 107.827, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 7.726021645880587, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 10.15034307709358, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 9.040340151825179, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.261655805287582, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 12.574081221217106, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 7.871348277556981, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 10.191122964842766, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.737033799493114, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 8.113340202953896, TRAIN_STAGE: 1\n",
            "in myloss function: summation 79.0, RMSE: 11.003753931524429, TRAIN_STAGE: 1\n",
            "Epoch 065: Loss: 95.696, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 19.0, RMSE: 8.158498899867404, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 11.925698809046876, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 13.152895379555337, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 10.880407252690347, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 9.332736244110638, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 8.53479326172796, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 7.402908073162212, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 9.464333356261088, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 11.097476355621357, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 9.09286667940939, TRAIN_STAGE: 1\n",
            "Epoch 066: Loss: 99.057, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 7.877691108079288, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 9.159704807294716, TRAIN_STAGE: 1\n",
            "in myloss function: summation 85.0, RMSE: 13.48550917136405, TRAIN_STAGE: 1\n",
            "in myloss function: summation 19.0, RMSE: 8.387469516527222, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 9.685677063248173, TRAIN_STAGE: 1\n",
            "in myloss function: summation 27.0, RMSE: 6.489102602897476, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 10.309354842018843, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 11.018804519823938, TRAIN_STAGE: 1\n",
            "in myloss function: summation 27.0, RMSE: 7.858190914662244, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 7.71901833953188, TRAIN_STAGE: 1\n",
            "Epoch 067: Loss: 92.005, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 10.596590895708172, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 9.933301711749463, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 11.498328960858297, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 8.71798669415446, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 7.924719057685595, TRAIN_STAGE: 1\n",
            "in myloss function: summation 73.0, RMSE: 10.503417996567283, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 6.289816863702791, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 10.314256155753991, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 7.344290939055844, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 7.243216936549468, TRAIN_STAGE: 1\n",
            "Epoch 068: Loss: 90.391, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 8.84817727891764, TRAIN_STAGE: 1\n",
            "in myloss function: summation 71.0, RMSE: 12.247361778655595, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.668267451514499, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 8.976378218888625, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 8.49179565641364, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 7.358305475173641, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 8.387304990097684, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 12.827440675702526, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 7.639071144524468, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 8.850082675167133, TRAIN_STAGE: 1\n",
            "Epoch 069: Loss: 92.308, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 8.480585197187658, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 10.348979143407472, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 10.66610224705848, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 8.740292560298286, TRAIN_STAGE: 1\n",
            "in myloss function: summation 16.0, RMSE: 6.271664302419104, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 7.797228195068273, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 5.994944036375028, TRAIN_STAGE: 1\n",
            "in myloss function: summation 75.0, RMSE: 12.884203954970852, TRAIN_STAGE: 1\n",
            "in myloss function: summation 57.0, RMSE: 10.742891478902157, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 11.234894137722497, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 070: Loss: 93.175, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 8.602592532645982, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 7.3568050110670935, TRAIN_STAGE: 1\n",
            "in myloss function: summation 81.0, RMSE: 11.873634736436255, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 8.782944440636246, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 11.49779614512952, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.751509270405045, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 10.027084811025784, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 11.683317519767334, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 9.325024996302979, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 9.57593356898286, TRAIN_STAGE: 1\n",
            "Epoch 071: Loss: 98.487, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 11.46206824394379, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 11.452217572601427, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 10.562731927217115, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 6.40798090623057, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 9.840351985402878, TRAIN_STAGE: 1\n",
            "in myloss function: summation 60.0, RMSE: 7.619209444140775, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 11.37490709888592, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 12.709328161283254, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 10.730688585737315, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.859757366383413, TRAIN_STAGE: 1\n",
            "Epoch 072: Loss: 102.033, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 9.243282034180321, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 8.17161249564585, TRAIN_STAGE: 1\n",
            "in myloss function: summation 20.0, RMSE: 9.431326525287052, TRAIN_STAGE: 1\n",
            "in myloss function: summation 67.0, RMSE: 9.129325450266181, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 8.189084772354517, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 8.578566607053753, TRAIN_STAGE: 1\n",
            "in myloss function: summation 26.0, RMSE: 7.838407215689329, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 10.691196253180062, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 11.066779878561213, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 7.6014354234551265, TRAIN_STAGE: 1\n",
            "Epoch 073: Loss: 89.953, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 8.983440294480536, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 11.904336668803078, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.685643723770653, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 11.077151103557444, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 11.654058011856796, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.411420224050934, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 8.30187934273733, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 7.2099472211361935, TRAIN_STAGE: 1\n",
            "in myloss function: summation 74.0, RMSE: 13.943703707647687, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 12.342274105276537, TRAIN_STAGE: 1\n",
            "Epoch 074: Loss: 103.539, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 62.0, RMSE: 8.554560898636675, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 6.360960458597107, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 7.926651401430923, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 12.60809911179651, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 8.733398442504178, TRAIN_STAGE: 1\n",
            "in myloss function: summation 65.0, RMSE: 12.187186256193337, TRAIN_STAGE: 1\n",
            "in myloss function: summation 17.0, RMSE: 7.418539378318489, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 11.694120084124247, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 11.977720475517481, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 8.272492942874182, TRAIN_STAGE: 1\n",
            "Epoch 075: Loss: 95.745, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 8.205106072107881, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 11.093860941895635, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 9.366897171084085, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 9.899361688931053, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 9.67541009100016, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 12.063024625437658, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 7.693030733450135, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.295738541409037, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 8.094786988527671, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.585453245686223, TRAIN_STAGE: 1\n",
            "Epoch 076: Loss: 93.980, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 9.273001280111739, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 8.970675522425564, TRAIN_STAGE: 1\n",
            "in myloss function: summation 50.0, RMSE: 10.173825480903387, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 8.744863918643274, TRAIN_STAGE: 1\n",
            "in myloss function: summation 72.0, RMSE: 10.2746694471714, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 10.854878833157123, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 6.518260856245137, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 9.411577490323626, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 7.95868043237196, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 12.00081596933567, TRAIN_STAGE: 1\n",
            "Epoch 077: Loss: 94.192, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 8.290539895668033, TRAIN_STAGE: 1\n",
            "in myloss function: summation 18.0, RMSE: 7.816677560271432, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 9.775857178891991, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 7.70940417017555, TRAIN_STAGE: 1\n",
            "in myloss function: summation 19.0, RMSE: 6.8702099857979455, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 9.533452391606712, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 7.917664338386122, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 10.50045670510045, TRAIN_STAGE: 1\n",
            "in myloss function: summation 47.0, RMSE: 9.66034450634277, TRAIN_STAGE: 1\n",
            "in myloss function: summation 18.0, RMSE: 7.052694648068514, TRAIN_STAGE: 1\n",
            "Epoch 078: Loss: 85.142, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 8.58816768966128, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 11.202132645972437, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 8.889911221549236, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 8.101071675448509, TRAIN_STAGE: 1\n",
            "in myloss function: summation 48.0, RMSE: 8.817032182977083, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 6.422805701047269, TRAIN_STAGE: 1\n",
            "in myloss function: summation 68.0, RMSE: 13.325982221644356, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 9.287044722171387, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 10.668414222559601, TRAIN_STAGE: 1\n",
            "in myloss function: summation 20.0, RMSE: 7.768115848582379, TRAIN_STAGE: 1\n",
            "Epoch 079: Loss: 93.079, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 12.12822585703681, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 9.69989982275687, TRAIN_STAGE: 1\n",
            "in myloss function: summation 46.0, RMSE: 9.39707402674371, TRAIN_STAGE: 1\n",
            "in myloss function: summation 21.0, RMSE: 8.534582501031194, TRAIN_STAGE: 1\n",
            "in myloss function: summation 11.0, RMSE: 6.562446065360241, TRAIN_STAGE: 1\n",
            "in myloss function: summation 61.0, RMSE: 11.150243136990603, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 12.109085981226432, TRAIN_STAGE: 1\n",
            "in myloss function: summation 43.0, RMSE: 9.5102568311884, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 13.894966320509312, TRAIN_STAGE: 1\n",
            "in myloss function: summation 17.0, RMSE: 8.107432889413746, TRAIN_STAGE: 1\n",
            "INFO:tensorflow:Assets written to: /content/Saved models/SIA_model_v12/assets\n",
            "Model Saved\n",
            "Epoch 080: Loss: 101.106, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 11.184162037283478, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 10.308460530938108, TRAIN_STAGE: 1\n",
            "in myloss function: summation 69.0, RMSE: 11.388234314064949, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 11.776761101987935, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 7.055358260463273, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 9.864330359508497, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.841064126797313, TRAIN_STAGE: 1\n",
            "in myloss function: summation 24.0, RMSE: 8.685830250942516, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 9.215649357359517, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 8.193561978014051, TRAIN_STAGE: 1\n",
            "Epoch 081: Loss: 96.523, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 9.949904812241616, TRAIN_STAGE: 1\n",
            "in myloss function: summation 51.0, RMSE: 10.25619451344472, TRAIN_STAGE: 1\n",
            "in myloss function: summation 55.0, RMSE: 11.210435556515668, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.274373705980839, TRAIN_STAGE: 1\n",
            "in myloss function: summation 63.0, RMSE: 14.083460304228847, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 9.181030726129869, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 10.70599398359354, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 7.491773002554389, TRAIN_STAGE: 1\n",
            "in myloss function: summation 18.0, RMSE: 7.119440257306129, TRAIN_STAGE: 1\n",
            "in myloss function: summation 56.0, RMSE: 9.581139292422735, TRAIN_STAGE: 1\n",
            "Epoch 082: Loss: 96.868, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 16.0, RMSE: 8.141650997841602, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 7.38161835707213, TRAIN_STAGE: 1\n",
            "in myloss function: summation 70.0, RMSE: 11.609580237278625, TRAIN_STAGE: 1\n",
            "in myloss function: summation 52.0, RMSE: 9.502725603963706, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 7.1119407218403, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 8.307796255387982, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 9.88640154145589, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 10.834783057581205, TRAIN_STAGE: 1\n",
            "in myloss function: summation 24.0, RMSE: 5.8770564937923115, TRAIN_STAGE: 1\n",
            "in myloss function: summation 27.0, RMSE: 6.4025567345631575, TRAIN_STAGE: 1\n",
            "Epoch 083: Loss: 85.069, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 64.0, RMSE: 11.842896315640939, TRAIN_STAGE: 1\n",
            "in myloss function: summation 53.0, RMSE: 9.472654466513069, TRAIN_STAGE: 1\n",
            "in myloss function: summation 40.0, RMSE: 9.075625191586138, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 9.402217116178155, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 9.368579281940603, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 11.679565943576115, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 8.29030499695164, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 9.026100400407103, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 7.364791547717636, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 8.345506958638985, TRAIN_STAGE: 1\n",
            "Epoch 084: Loss: 93.875, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 6.625872098085745, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 9.443176815240884, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 9.913593812300848, TRAIN_STAGE: 1\n",
            "in myloss function: summation 38.0, RMSE: 8.515707446289179, TRAIN_STAGE: 1\n",
            "in myloss function: summation 18.0, RMSE: 8.627044817098556, TRAIN_STAGE: 1\n",
            "in myloss function: summation 29.0, RMSE: 8.772137686265616, TRAIN_STAGE: 1\n",
            "in myloss function: summation 23.0, RMSE: 9.376914118403196, TRAIN_STAGE: 1\n",
            "in myloss function: summation 32.0, RMSE: 8.788331832242095, TRAIN_STAGE: 1\n",
            "in myloss function: summation 60.0, RMSE: 10.19409585336317, TRAIN_STAGE: 1\n",
            "in myloss function: summation 22.0, RMSE: 7.279364279544499, TRAIN_STAGE: 1\n",
            "Epoch 085: Loss: 87.544, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 44.0, RMSE: 7.767033317649202, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 10.25638541313875, TRAIN_STAGE: 1\n",
            "in myloss function: summation 36.0, RMSE: 6.793762312643914, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 7.034222879016255, TRAIN_STAGE: 1\n",
            "in myloss function: summation 59.0, RMSE: 12.266966884222157, TRAIN_STAGE: 1\n",
            "in myloss function: summation 49.0, RMSE: 11.090613957240967, TRAIN_STAGE: 1\n",
            "in myloss function: summation 25.0, RMSE: 6.278046001081391, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 11.88055154893466, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.411393580206399, TRAIN_STAGE: 1\n",
            "in myloss function: summation 28.0, RMSE: 6.2701512303042035, TRAIN_STAGE: 1\n",
            "Epoch 086: Loss: 87.061, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 45.0, RMSE: 8.645309206438064, TRAIN_STAGE: 1\n",
            "in myloss function: summation 35.0, RMSE: 11.920401350712737, TRAIN_STAGE: 1\n",
            "in myloss function: summation 42.0, RMSE: 8.958963663006818, TRAIN_STAGE: 1\n",
            "in myloss function: summation 30.0, RMSE: 8.71446713012564, TRAIN_STAGE: 1\n",
            "in myloss function: summation 33.0, RMSE: 9.17095382953062, TRAIN_STAGE: 1\n",
            "in myloss function: summation 39.0, RMSE: 11.779497146348442, TRAIN_STAGE: 1\n",
            "in myloss function: summation 26.0, RMSE: 8.279641152823103, TRAIN_STAGE: 1\n",
            "in myloss function: summation 66.0, RMSE: 12.238587659295778, TRAIN_STAGE: 1\n",
            "in myloss function: summation 58.0, RMSE: 12.24859665888703, TRAIN_STAGE: 1\n",
            "in myloss function: summation 31.0, RMSE: 7.098665711023615, TRAIN_STAGE: 1\n",
            "Epoch 087: Loss: 99.073, Accuracy: 0.000%, TRAIN_STAGE: 1\n",
            "in myloss function: summation 24.0, RMSE: 9.583291903090789, TRAIN_STAGE: 1\n",
            "in myloss function: summation 54.0, RMSE: 9.747663784542876, TRAIN_STAGE: 1\n",
            "in myloss function: summation 78.0, RMSE: 13.955827282514395, TRAIN_STAGE: 1\n",
            "in myloss function: summation 41.0, RMSE: 8.663454059025005, TRAIN_STAGE: 1\n",
            "in myloss function: summation 34.0, RMSE: 7.783874919079672, TRAIN_STAGE: 1\n",
            "in myloss function: summation 37.0, RMSE: 8.637942752588927, TRAIN_STAGE: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Gi59NscGC4Sz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the model\n",
        "# load_model = tf.keras.models.load_model('/content/Saved models/SIA_model_v12')\n",
        "# load_model.trainable_variables"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7Ccx3LPcC4S4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_x_train(x_train):    \n",
        "    fig = go.Figure() \n",
        "    x = np.arange(x_train[1].shape[1])\n",
        "    for i in range(len(x_train[1])):\n",
        "        fig.add_trace(go.Scatter(x=x, y=np.reshape(x_train[0][i][:],28),name='0'))\n",
        "        fig.add_trace(go.Scatter(x=x, y=np.reshape(x_train[1][i][:],28),name='1'))\n",
        "    fig.show()\n",
        "def plot_batch(batch):    \n",
        "    fig = go.Figure()\n",
        "    x = np.arange(batch.shape[1])\n",
        "    fig.add_trace(go.Scatter(x=x, y=np.reshape(batch, 28),name='batch'))\n",
        "    fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "U4nKlCM1C4TC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def last_batch_from_train_data(series, size=DAYS_PRED, x=0):      \n",
        "    \n",
        "    left_index=series.shape[0]-size   \n",
        "    right_index=series.shape[0]    \n",
        "       \n",
        "    batch_1=series.iloc[left_index:right_index,1]\n",
        "    batch_2=series.iloc[left_index:right_index,1]    \n",
        "    \n",
        "    batch_1 = tf.transpose(np.expand_dims(batch_1,axis=0))\n",
        "    batch_2 = tf.transpose(np.expand_dims(batch_2,axis=0))\n",
        "    batch_1 = np.expand_dims(batch_1,axis=0)\n",
        "    batch_2 = np.expand_dims(batch_2,axis=0) \n",
        "    batch_2 = np.roll(batch_2,-1)\n",
        "    \n",
        "    return batch_1, batch_2\n",
        "batch_1, batch_2 = last_batch_from_train_data(train_data)\n",
        "batch_1 = np.copy(batch_1)\n",
        "batch_2 = np.copy(batch_2)\n",
        "\n",
        "# print(batch_1,batch_2)\n",
        "# batch_2[0,27,0]=2\n",
        "# print(model([batch_1.astype(float), batch_2.astype(float)]).numpy())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "sWo3HdTuC4TF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot_batch(batch_1)\n",
        "# plot_batch(batch_2)\n",
        "model2=create_model()\n",
        "print(np.asarray(model2.trainable_variables)-np.asarray(model.trainable_variables))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "dLXiUPecC4TI",
        "colab_type": "code",
        "outputId": "16caed13-d031-43ce-b065-0d070d912302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "source": [
        "#Load the model\n",
        "if not 'model' in locals():\n",
        "  model = tf.keras.models.load_model('/content/Saved models/SIA_model_v12')\n",
        "\n",
        "\n",
        "# One test view on model working\n",
        "batch_test_1, batch_test_2, batch_true = test_batch_ri_from_train_data(train_data, r_i=800)\n",
        "prediction=f28_days_prediction(model,batch_test_1,batch_test_2)\n",
        "fig = go.Figure()\n",
        "x = np.arange(len(prediction))\n",
        "fig.add_trace(go.Scatter(x=x, y=np.reshape(batch_test_1,28), name ='pre_interval'))\n",
        "x = np.arange(len(prediction),len(prediction)+DAYS_PRED)\n",
        "fig.add_trace(go.Scatter(x=x, y=prediction, name ='prediction'))\n",
        "fig.add_trace(go.Scatter(x=x, y=np.reshape(batch_true,28), name ='true'))\n",
        "fig.show()\n",
        "\n",
        " \n",
        "print(f\"model prediction: \\n \\\n",
        "    {rmsse(np.reshape(batch_true,28),prediction)}\")\n",
        "\n",
        "print(f\"ones line prediction: \\n \\\n",
        "    {rmsse(np.reshape(batch_true,28),np.ones(28))}\")\n",
        "\n",
        "print(f\" sum on true: {np.sum(np.reshape(batch_true,28))}, sum on prediction: {np.sum(prediction)}\")"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"0a96da80-cdd4-4a0d-9f73-fd30da0d6e07\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"0a96da80-cdd4-4a0d-9f73-fd30da0d6e07\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '0a96da80-cdd4-4a0d-9f73-fd30da0d6e07',\n",
              "                        [{\"name\": \"pre_interval\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27], \"y\": [1, 1, 1, 0, 0, 0, 0, 0, 1, 2, 2, 0, 1, 0, 0, 0, 0, 1, 2, 1, 0, 0, 0, 0, 0, 1, 0, 3]}, {\"name\": \"prediction\", \"type\": \"scatter\", \"x\": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], \"y\": [1.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}, {\"name\": \"true\", \"type\": \"scatter\", \"x\": [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55], \"y\": [1, 2, 1, 0, 3, 0, 0, 0, 1, 0, 2, 2, 1, 0, 0, 1, 2, 0, 1, 0, 1, 4, 0, 0, 5, 0, 0, 0]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0a96da80-cdd4-4a0d-9f73-fd30da0d6e07');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "model prediction: \n",
            "     1.546886273407694\n",
            "ones line prediction: \n",
            "     1.2955969390869324\n",
            " sum on true: 27, sum on prediction: 18.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "d4fneRDOC4TO",
        "colab_type": "code",
        "outputId": "9776662c-01f5-4ccb-ee49-2205d54ccad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "#Load the model\n",
        "if not 'model' in locals():\n",
        "  model = tf.keras.models.load_model('/content/Saved models/SIA_model_v12')\n",
        "\n",
        "test_summation=[]\n",
        "test_rmse=[]\n",
        "\n",
        "for _ in range(5):\n",
        "    summation, rmse = validation(model,display=True)\n",
        "    test_summation.append(summation)\n",
        "    test_rmse.append(rmse)\n",
        "print(f\"test summation: {sum(test_summation)}, test rmse: {sum(test_rmse)}\")"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_true sum: 21, y_pred sum: 18.0\n",
            "y_true sum: 19, y_pred sum: 19.0\n",
            "y_true sum: 11, y_pred sum: 10.0\n",
            "y_true sum: 14, y_pred sum: 24.0\n",
            "y_true sum: 25, y_pred sum: 22.0\n",
            " summation: 17.0\n",
            " RMSE: 7.0930807214873415\n",
            "y_true sum: 25, y_pred sum: 23.0\n",
            "y_true sum: 14, y_pred sum: 16.0\n",
            "y_true sum: 18, y_pred sum: 23.0\n",
            "y_true sum: 20, y_pred sum: 22.0\n",
            "y_true sum: 20, y_pred sum: 21.0\n",
            " summation: 12.0\n",
            " RMSE: 8.761575179739424\n",
            "y_true sum: 23, y_pred sum: 22.0\n",
            "y_true sum: 22, y_pred sum: 23.0\n",
            "y_true sum: 14, y_pred sum: 17.0\n",
            "y_true sum: 15, y_pred sum: 19.0\n",
            "y_true sum: 17, y_pred sum: 12.0\n",
            " summation: 14.0\n",
            " RMSE: 5.928721084547755\n",
            "y_true sum: 8, y_pred sum: 21.0\n",
            "y_true sum: 28, y_pred sum: 21.0\n",
            "y_true sum: 11, y_pred sum: 14.0\n",
            "y_true sum: 17, y_pred sum: 19.0\n",
            "y_true sum: 21, y_pred sum: 23.0\n",
            " summation: 27.0\n",
            " RMSE: 7.358995456264516\n",
            "y_true sum: 8, y_pred sum: 19.0\n",
            "y_true sum: 13, y_pred sum: 21.0\n",
            "y_true sum: 22, y_pred sum: 19.0\n",
            "y_true sum: 24, y_pred sum: 23.0\n",
            "y_true sum: 8, y_pred sum: 19.0\n",
            " summation: 34.0\n",
            " RMSE: 7.479925305124562\n",
            "test summation: 104.0, test rmse: 36.6222977471636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "g7-CWX0wC4TS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# i = np.random.choice(train_data.index.values)\n",
        "# print(train_data.index.values.shape)\n",
        "# print(i)\n",
        "# i=1835\n",
        "# test_batch_ri_from_train_data(train_data, r_i=900)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}